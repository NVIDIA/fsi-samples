{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asian Barrier Options Pricing using GPU Acceleration\n",
    "    1. CuPy, Numba and CPU Monte-Carlo Pricing\n",
    "    2. Batched Monte-Carlo Pricing\n",
    "    3. Approximation using Deep Learning derivatives \n",
    "    4. Mixed Precision and multiple GPUs \n",
    "    5. TensorRT inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The European and American Options price can be estimated accurately by the efficient [Black–Scholes model](https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model). Options like [Barrier Option](https://en.wikipedia.org/wiki/Barrier_option) and [Basket Option](https://en.wikipedia.org/wiki/Basket_option) have a complicated structure with no simple analytical solution. The Monte Carlo simulation is an effective way to price them. To get an accurate price with a small variance, a large number of simulation paths are needed which is computationally intensive. Luckily, each of the simulation paths are independent and we can take advantage of the multiple core GPU to accelerate the computation. Using GPU can speedup the computation by orders of magnitude due to the parallelization of the independent paths. But even that is still not fast enough. Recently, [Deep learning derivatives method](https://arxiv.org/pdf/1809.02233.pdf) was introduced to value derivatives and achieves speedup even higher than the former.  \n",
    "\n",
    "In this tutorial, we are going to use Monte Carlo methods to price the [Down-and-Out](https://www.investopedia.com/terms/d/daoo.asp) [Asian](https://www.investopedia.com/terms/a/asianoption.asp) [Barrier](https://www.investopedia.com/terms/b/barrieroption.asp) [Call Option](https://www.investopedia.com/terms/c/calloption.asp) :\n",
    "\n",
    "Steps:\n",
    "    1. Use Python GPU libraries to accelerate the Monte Carlo pricing on the GPU\n",
    "    2. Use the Monte Carlo pricing dataset to train a simple Barrier Option Pricing Neural Network Model\n",
    "    3. Accelerate the neural network inference by TensorRT\n",
    "    \n",
    "### Barrier Option pricing\n",
    "\n",
    "Asian Barrier Option is a mixture of [Asian Option](https://en.wikipedia.org/wiki/Asian_option) and [Barrier Option](https://en.wikipedia.org/wiki/Barrier_option). The price depends on the average underlying Asset Price `S`, the Strick Price `K` and the Barrier Price `B`. There are 4 types of Barrier Options:-\n",
    "   * [Up-and-out](https://www.investopedia.com/terms/u/up-and-outoption.asp): spot price starts below the barrier level and has to move up for the option to be knocked out.\n",
    "   * [Down-and-out](https://www.investopedia.com/terms/d/daoo.asp): spot price starts above the barrier level and has to move down for the option to be knocked out.\n",
    "   * [Up-and-in](https://www.investopedia.com/terms/u/up-and-inoption.asp): spot price starts below the barrier level and has to move up for the option to become activated.\n",
    "   * [Down-and-in](https://www.investopedia.com/terms/d/daio.asp): spot price starts above the barrier level and has to move down for the option to become activated.\n",
    "\n",
    "Without loss of generality, in this notebook we will use the [Down-and-Out Call Discretized Asian Barrier Option](https://ieeexplore.ieee.org/document/6327776/metrics#metrics) as an example. The option will be void if the average price of the underlying asset goes below the barrier. The asset Spot Price `S` is usually modeled as [Geometric Brownian motion](https://en.wikipedia.org/wiki/Geometric_Brownian_motion), which has 3 free parameters:- [Spot Price](https://www.investopedia.com/terms/s/spotprice.asp), [Percent Volatility](https://www.investopedia.com/terms/v/volatility.asp) and the [Percent Drift](https://en.wikipedia.org/wiki/Stochastic_drift). The price of the option will be the expected profit at the maturity discount to the current value.\n",
    "\n",
    "Due to the complicated nature of the barrier and price algorithmic averaging, there is no analytical solution for this example of [exotic option](https://www.investopedia.com/terms/e/exoticoption.asp). We can use the Monte Carlo simulation method to estimate the expected value of profit on the maturity day. \n",
    "\n",
    "Following are the parameters we choose to price the example option:-\n",
    "\n",
    "    Maturity (T): 1 year\n",
    "    Spot (S) : 120\n",
    "    Strike (K): 110\n",
    "    Volatility (sigma): 35.0 %\n",
    "    Risk Free Rate (r): 5.0 %\n",
    "    Stock Drift Rate (mu): 10.0 %\n",
    "    Barrier (B): 100\n",
    "\n",
    "As we know the [Standard Error of the Mean](https://en.wikipedia.org/wiki/Standard_error) is proportional to the inversed square root of the number of samples. Hence the more simulation paths we have, the more accurate the pricing will be. We set the constants for the option and load the necessary libraries:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numba\n",
    "from numba import cuda\n",
    "from numba import njit\n",
    "from numba import prange\n",
    "import cudf\n",
    "\n",
    "N_PATHS = 8192000\n",
    "N_STEPS = 365\n",
    "T = 1.0\n",
    "K = 110.0\n",
    "B = 100.0\n",
    "S0 = 120.0\n",
    "sigma = 0.35\n",
    "mu = 0.1\n",
    "r = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simulate 10 million paths with 365 steps where each step represents a day. \n",
    "\n",
    "#### Single Thread CPU\n",
    "The single thread CPU code for the Monte Carlo simulation has two nested for-loops. The outer loop iterates each path while the inner loop iterates time and computes the underlying asset price for that day. Note that this code is accelerated via [Numba @jit](http://numba.pydata.org/) hence it compiles into machine code at runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def cpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    tmp1 = mu*T/N_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(T/N_STEPS)\n",
    "    running_average = 0.0\n",
    "    for i in range(N_PATHS):\n",
    "        s_curr = S0\n",
    "        for n in range(N_STEPS):\n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n",
    "            if running_average <= B:\n",
    "                break\n",
    "\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  We use CuPy to generate Gaussian random numbers in the GPU and allocate an array to store the prices at maturity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
    "randoms_cpu = np_randoms = cupy.asnumpy(randoms_gpu)\n",
    "output =  np.zeros(N_PATHS, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the Monte Carlo simulation and time it. When the Numba accelerated function is called for the first time, there is some overhead to compile it. So to time it accurately, we run this method twice and and consider the run time of the second attempt. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 33.31781530380249 v 18.7093\n"
     ]
    }
   ],
   "source": [
    "cpu_barrier_option(output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
    "s = time.time()\n",
    "cpu_barrier_option(output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
    "v = output.mean()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Cores CPU\n",
    "CPU has multiple cores and to make a fair comparison, the code can be modified a little to take advantage of all the CPU cores. Note how we parallelize the outer loop:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True, parallel=True)\n",
    "def cpu_multiplecore_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    tmp1 = mu*T/N_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(T/N_STEPS)\n",
    "    for i in prange(N_PATHS):\n",
    "        s_curr = S0\n",
    "        running_average = 0.0\n",
    "        for n in range(N_STEPS):\n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n",
    "            if running_average <= B:\n",
    "                break\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this parallel code and timing it:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 4.055903911590576 v 18.7093\n"
     ]
    }
   ],
   "source": [
    "cpu_multiplecore_barrier_option(output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
    "s = time.time()\n",
    "cpu_multiplecore_barrier_option(output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
    "v = output.mean()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see aproximately 32x speedup due to 32 cores of the CPU. \n",
    "\n",
    "#### NUMBA GPU\n",
    "The multiple cores CPU code can be modified easily to run in the GPU via Numba.cuda.jit. The code below is very similar to the CPU multiple core code except that we parallize the outer loop on the GPU. Running this code and timing it:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def numba_gpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    # ii - overall thread index\n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "    tmp1 = mu*T/N_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(T/N_STEPS)\n",
    "    running_average = 0.0\n",
    "    for i in range(ii, N_PATHS, stride):\n",
    "        s_curr = S0\n",
    "        for n in range(N_STEPS):\n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average += (s_curr - running_average) / (n + 1.0)\n",
    "            if running_average <= B:\n",
    "                break\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.07474923133850098 v 18.709291\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_threads = 256\n",
    "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "s = time.time()\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "v = output.mean()\n",
    "cuda.synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 4x speedup compared to the mutliple core version and 128x speedup compared to the single core version. \n",
    "\n",
    "#### NUMBA Shared Memory \n",
    "While accessing the global memory for Gaussian random numbers, the memory access is already aligned and numbers are only read once. So using shared memory is not helping the performace as shown below:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def numba_gpu_barrier_option_shared_mem(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    shared = cuda.shared.array(shape=0, dtype=numba.float32)\n",
    "    # load to shared memory\n",
    "    path_offset = cuda.blockIdx.x * cuda.blockDim.x\n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "    tmp1 = mu*T/N_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(T/N_STEPS)\n",
    "    running_average = 0.0\n",
    "    for i in range(ii, N_PATHS, stride):\n",
    "        s_curr = S0\n",
    "        for n in range(N_STEPS):\n",
    "            shared[cuda.threadIdx.x] = d_normals[path_offset + cuda.threadIdx.x + n * N_PATHS]\n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*shared[cuda.threadIdx.x]\n",
    "            running_average += (s_curr - running_average) / (n + 1.0)\n",
    "            if running_average <= B:\n",
    "                break\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.08823490142822266 v 18.709291\n"
     ]
    }
   ],
   "source": [
    "number_of_threads = 256\n",
    "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
    "shared_buffer_size = number_of_threads * 4\n",
    "numba_gpu_barrier_option_shared_mem[(number_of_blocks,), (number_of_threads,), 0, shared_buffer_size](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "s = time.time()\n",
    "numba_gpu_barrier_option_shared_mem[(number_of_blocks,), (number_of_threads,), 0, shared_buffer_size](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "v = output.mean()\n",
    "cuda.synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUPY GPU\n",
    "CuPy provides an easy way to define GPU kernels from raw CUDA source. `RawKernel` object allows you to call the kernel with CUDA’s `cuLaunchKernel` interface. Here is an example where we wrap the Barrier Option computation code inside the `RawKernel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy_barrier_option = cupy.RawKernel(r'''\n",
    "extern \"C\" __global__ void barrier_option(\n",
    "    float *d_s,\n",
    "    const float T,\n",
    "    const float K,\n",
    "    const float B,\n",
    "    const float S0,\n",
    "    const float sigma,\n",
    "    const float mu,\n",
    "    const float r,\n",
    "    const float * d_normals,\n",
    "    const long N_STEPS,\n",
    "    const long N_PATHS)\n",
    "{\n",
    "  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  unsigned stride = blockDim.x * gridDim.x;\n",
    "  unsigned tid = threadIdx.x;\n",
    "\n",
    "  const float tmp1 = mu*T/N_STEPS;\n",
    "  const float tmp2 = exp(-r*T);\n",
    "  const float tmp3 = sqrt(T/N_STEPS);\n",
    "  double running_average = 0.0;\n",
    "\n",
    "  for (unsigned i = idx; i<N_PATHS; i+=stride)\n",
    "  {\n",
    "    float s_curr = S0;\n",
    "    unsigned n=0;\n",
    "    for(unsigned n = 0; n < N_STEPS; n++){\n",
    "       s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS];\n",
    "       running_average += (s_curr - running_average) / (n + 1.0) ;\n",
    "       if (running_average <= B){\n",
    "           break;\n",
    "       }\n",
    "    }\n",
    "\n",
    "    float payoff = (running_average>K ? running_average-K : 0.f);\n",
    "    d_s[i] = tmp2 * payoff;\n",
    "  }\n",
    "}\n",
    "\n",
    "''', 'barrier_option')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can launch it to compute the same Barrier Option price:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.03548622131347656 v 18.70929\n"
     ]
    }
   ],
   "source": [
    "number_of_threads = 256\n",
    "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "s = time.time()\n",
    "cupy_barrier_option((number_of_blocks,), (number_of_threads,),\n",
    "                   (output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r),  randoms_gpu, N_STEPS, N_PATHS))\n",
    "v = output.mean()\n",
    "cupy.cuda.stream.get_current_stream().synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v',v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is the most efficient way to use the GPU and it achieves 8x speedup compared to the 32 core CPU performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple GPUs Option Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more accurate estimation of the option price, more paths are needed for Monte Carlo simulation. The single V100 GPU we used in the above example only has 32GB memory and we are hitting the memory limits to run 8M simulations. [DASK](https://dask.org/) is an integrated component of RAPIDS for distributed computation on GPUs.  We can take advantage of it to distribute the Monte Carlo simulation computation to multiple nodes across multiple GPUs. First, we need to wrap all the computation inside a function to allow the allocated GPU memory to be released at the end of the function call. Note that the function takes an extra argument for the random number seed value so the individual function calls each have an independent sequence of random numbers. Loading the DASK library and setting up the local CUDA cluster :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the GPU memory\n",
    "del randoms_gpu \n",
    "del randoms_cpu\n",
    "del output\n",
    "\n",
    "def get_option_price(T, K, B, S0, sigma, mu, r, N_PATHS = 8192000, N_STEPS = 365, seed=3):\n",
    "    number_of_threads = 256\n",
    "    number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "    cupy.random.seed(seed)\n",
    "    randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
    "    output =  cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
    "    cupy_barrier_option((number_of_blocks,), (number_of_threads,),\n",
    "                   (output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r),  randoms_gpu, N_STEPS, N_PATHS))\n",
    "    v = output.mean()\n",
    "    out_df = cudf.DataFrame()\n",
    "    out_df['p'] = cudf.Series([v.item()])\n",
    "    return out_df\n",
    "o = get_option_price(T=1.0, K=120.0, B=90.0, S0=100.0, sigma=0.2, mu=0.1, r=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:40199</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>270.39 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:40199' processes=4 threads=4, memory=270.39 GB>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "import dask_cudf\n",
    "from dask.delayed import delayed\n",
    "from dask_cuda import LocalCUDACluster\n",
    "cluster = LocalCUDACluster()\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 GPUs inside the system. To distribute the above function, we wrap it into the `delayed` function to integrate it into the DASK computation graph. We use `from_delayed` to gather all the distributed dataframes into a holistic cudf_dask dataframe. We can call the cudf_dask dataframe `mean` and `std` to calculate the expected mean and standard deviation of the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dask_cudf.from_delayed([delayed(get_option_price)(T=1.0, K=110.0, B=100.0, S0=120.0, sigma=0.35, mu=0.1, r=0.05, seed=3000+i) for i in range(1600)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    18.711432\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.std().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code computed 1600 Monte Carlo simulations of `8192000` paths. By averaging the price together to get a better estimation, the standard deviation is reduced by a factor of 1/sqrt(1600) = 1/40  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
