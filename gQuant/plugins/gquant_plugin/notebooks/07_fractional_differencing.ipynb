{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fractional Differencing\n",
    "\n",
    "### Background\n",
    "Fractional Differencing is a signal processing technique that is used to remove the non-stationarity from the time series while maintaining as much memory as possible. It is widely used in FSI to prepare training data for machine learning algorithms. In this [open-source project](https://github.com/ritchieng/fractional_differencing_gpu/blob/master/notebooks/gpu_fractional_differencing.ipynb) done by Ensemble Capital, fractional differencing computation is accelerated via `cudf.appy_chunk` method in the GPU. It achieves hundreds of times acceleration compared with CPU implementation in their [report](https://www.researchgate.net/publication/335159299_GFD_GPU_Fractional_Differencing_for_Rapid_Large-scale_Stationarizing_of_Time_Series_Data_while_Minimizing_Memory_Loss). \n",
    "Using `apply_rows` and `apply_chunks` method from the cudf library is the easiest way of customizing GPU computations as covered in this [blog](https://medium.com/rapids-ai/user-defined-functions-in-rapids-cudf-2d7c3fc2728d). However, it is not the most efficient way.\n",
    "\n",
    "In this notebook, we are going to show how to use Numba to do fractional differencing computation efficiently. As greenflow wrap the fractional differencing function in the computation node, we are going to show it is easy for data scientists to compute fractional differencing signals and use them to generate alpha signals. \n",
    "\n",
    "### Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "import warnings\n",
    "import greenflow\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import cudf\n",
    "import inspect\n",
    "from numba import njit\n",
    "from numba import prange\n",
    "from greenflow.dataframe_flow.task import load_modules\n",
    "from greenflow_gquant_plugin.cuindicator import get_weights_floored, fractional_diff\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the fractional differencing code from the [open-source project](https://github.com/ritchieng/fractional_differencing_gpu/blob/master/notebooks/gpu_fractional_differencing.ipynb). We will use this as our benchmark reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_dot_product_kernel(in_data, out, window_size, weights):\n",
    "    # Set the first window_size-1 rows in each chunk to np.nan due \n",
    "    # insufficient history\n",
    "    for i in range(cuda.threadIdx.x, window_size - 1, cuda.blockDim.x):\n",
    "        out[i] = np.nan\n",
    "    \n",
    "    # Compute dot product of preceding window_size rows\n",
    "    for i in range(cuda.threadIdx.x + window_size - 1, in_data.size, cuda.blockDim.x):\n",
    "        rolling_dot_product = 0.0\n",
    "        \n",
    "        k = 0\n",
    "        for j in range(i - window_size + 1, i + 1):\n",
    "            rolling_dot_product += in_data[j] * weights[k][0]\n",
    "            k += 1\n",
    "        \n",
    "        out[i] = rolling_dot_product \n",
    "        \n",
    "def frac_diff_gpu(df, d, floor=1e-3):\n",
    "    r\"\"\"Fractionally difference time series via GPU.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe of raw time series values.\n",
    "        d (float): differencing value from 0 to 1 where > 1 has no FD.\n",
    "        floor (float): minimum value of weights, ignoring anything smaller.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Bring dataframe to GPU, reset index for GPU dot product kernel\n",
    "    # gdf_raw = cudf.from_pandas(df).reset_index(drop=True)\n",
    "    gdf_raw = df\n",
    "    gdf_raw.columns = ['in_data']\n",
    "\n",
    "    # Get weights window\n",
    "    weights = get_weights_floored(d=d, num_k=len(gdf_raw), floor=floor)\n",
    "    weights_window_size = len(weights)\n",
    "    \n",
    "    # Reverse weights and as contiguous\n",
    "    weights = np.ascontiguousarray(weights[::-1])\n",
    "    \n",
    "    # Bring weights to GPU\n",
    "    gdf_weights = cudf.DataFrame()\n",
    "    gdf_weights[gdf_raw.columns[0]] = weights.reshape(-1)\n",
    "\n",
    "    # Length of data\n",
    "    data_length = len(gdf_raw)\n",
    "\n",
    "    # T4: max of 518 threads per block.\n",
    "    # V100: max 1024 threads per block\n",
    "    threads_per_block = 518\n",
    "\n",
    "    # Chunk size split\n",
    "    # This has to be improved, but as a v0.1, it's sufficient to show speed-up\n",
    "    # Up to easily 100 million data points\n",
    "    trunk_size = data_length\n",
    "\n",
    "    # Get fractionally differenced time series through GPU function\n",
    "    gdf_raw_fd = gdf_raw.apply_chunks(moving_dot_product_kernel,\n",
    "                                 incols=['in_data'],\n",
    "                                 outcols=dict(out=np.float64),\n",
    "                                 kwargs=dict(window_size=weights_window_size, weights=weights),\n",
    "                                 chunks=list(range(0, data_length, trunk_size)) + [data_length],\n",
    "                                 tpb=threads_per_block)\n",
    "    \n",
    "    # Bring to CPU for normal manipulation\n",
    "    # df_raw_fd = gdf_raw_fd.to_pandas().dropna().iloc[:-1, 1]\n",
    "    \n",
    "    return gdf_raw_fd, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the greenflow's fractional differencing implementation via Numba library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fractional_diff(input_arr, d=0.5, floor=1e-3, min_periods=None,\n",
      "                    thread_tile=2, number_of_threads=512):\n",
      "    \"\"\"\n",
      "    The fractional difference computation method.\n",
      "\n",
      "    Arguments:\n",
      "    -------\n",
      "      input_arr: numba.cuda.DeviceNDArray or cudf.Series\n",
      "        the input array to compute the fractional difference\n",
      "      d: float\n",
      "        the differencing value. range from 0 to 1\n",
      "      floor: float\n",
      "        minimum value for the weights for computational efficiency.\n",
      "      min_periods: int\n",
      "        default the lengths of the weights. Need at least min_periods of\n",
      "        non-na elements to get fractional difference value\n",
      "      thread_tile: int\n",
      "        each thread will be responsible for `thread_tile` number of\n",
      "        elements in window computation\n",
      "      number_of_threads: int\n",
      "        number of threads in a block for CUDA computation\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    (numba.cuda.DeviceNDArray, np.array)\n",
      "        the computed fractional difference array and the weight array tuple\n",
      "\n",
      "    \"\"\"\n",
      "    if isinstance(input_arr, numba.cuda.cudadrv.devicearray.DeviceNDArray):\n",
      "        gpu_in = input_arr\n",
      "    else:\n",
      "        gpu_in = input_arr.to_gpu_array()\n",
      "\n",
      "    # compute the weights for the fractional difference\n",
      "    weights = get_weights_floored(d=d,\n",
      "                                  num_k=len(input_arr),\n",
      "                                  floor=floor)[::-1, 0]\n",
      "    weights_out = np.ascontiguousarray(weights)\n",
      "    weights = numba.cuda.to_device(weights_out)\n",
      "\n",
      "    window = len(weights)\n",
      "\n",
      "    if min_periods is None:\n",
      "        min_periods = window\n",
      "    else:\n",
      "        min_periods = min_periods\n",
      "\n",
      "    number_of_threads = number_of_threads\n",
      "    array_len = len(gpu_in)\n",
      "\n",
      "    # allocate the output array\n",
      "    gpu_out = numba.cuda.device_array_like(gpu_in)\n",
      "\n",
      "    number_of_blocks = \\\n",
      "        (array_len + (number_of_threads * thread_tile - 1)) // \\\n",
      "        (number_of_threads * thread_tile)\n",
      "\n",
      "    shared_buffer_size = (number_of_threads * thread_tile +\n",
      "                          window - 1 + window)\n",
      "\n",
      "    # call the conv kernel\n",
      "    kernel[(number_of_blocks,),\n",
      "           (number_of_threads,),\n",
      "           0,\n",
      "           shared_buffer_size * 8](gpu_in,\n",
      "                                   weights,\n",
      "                                   gpu_out,\n",
      "                                   window,\n",
      "                                   array_len,\n",
      "                                   thread_tile,\n",
      "                                   min_periods)\n",
      "    return gpu_out, weights_out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(fractional_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It launches the Numba kernel, which defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def conv_window(shared, history_len, out_arr, window_size,\n",
    "                arr_len, offset, offset2, min_size):\n",
    "    \"\"\"\n",
    "    This function is to do convolution for one thread\n",
    "\n",
    "    Arguments:\n",
    "    ------\n",
    "     shared: numba.cuda.DeviceNDArray\n",
    "        3 chunks of data are stored in the shared memory\n",
    "        the first [0, window_size) elements is the chunk of data that is\n",
    "        necessary to compute the first convolution element.\n",
    "        then [window_size, window_size + thread_tile * blockDim) elements\n",
    "        are the inputs allocated for this block of threads\n",
    "        the last [window_size + thread_tile,\n",
    "        window_size + thread_tile + window_size) is to store the kernel values\n",
    "     history_len: int\n",
    "        total number of historical elements available for this chunk of data\n",
    "     out_arr: numba.cuda.DeviceNDArray\n",
    "        output gpu_array of size of `thread_tile`\n",
    "     window_size: int\n",
    "        the number of elements in the kernel\n",
    "     arr_len: int\n",
    "        the chunk array length, same as `thread_tile`\n",
    "     offset: int\n",
    "        indicate the starting index of the chunk array in the shared for\n",
    "        this thread.\n",
    "     offset: int\n",
    "        indicate the starting position of the weights/kernel array\n",
    "     min_size: int\n",
    "         the minimum number of non-na elements\n",
    "    \"\"\"\n",
    "    for i in range(arr_len):\n",
    "        if i + history_len < window_size-1:\n",
    "            out_arr[i] = np.nan\n",
    "        else:\n",
    "            s = 0.0\n",
    "            average_size = 0\n",
    "            for j in range(0, window_size):\n",
    "                if not (cmath.isnan(\n",
    "                        shared[offset + i - j])):\n",
    "                    s += (shared[offset + i - j] *\n",
    "                          shared[offset2 + window_size - 1 - j])\n",
    "                    average_size += 1\n",
    "            if average_size >= min_size:\n",
    "                out_arr[i] = s\n",
    "            else:\n",
    "                out_arr[i] = np.nan\n",
    "\n",
    "                \n",
    "@cuda.jit\n",
    "def kernel(in_arr, weight_arr, out_arr, window,\n",
    "           arr_len, thread_tile, min_size):\n",
    "    \"\"\"\n",
    "    This kernel is to do 1D convlution on `in_arr` array with `weight_arr`\n",
    "    as kernel. The results is saved on `out_arr`.\n",
    "\n",
    "    Arguments:\n",
    "    ------\n",
    "     in_arr: numba.cuda.DeviceNDArray\n",
    "        input gpu array\n",
    "     weight_arr: numba.cuda.DeviceNDArray\n",
    "        convolution kernel gpu array\n",
    "     out_arr: numba.cuda.DeviceNDArray\n",
    "        output gpu_array\n",
    "     window: int\n",
    "        the number of elements in the weight_arr\n",
    "     arr_len: int\n",
    "        the input/output array length\n",
    "     thread_tile: int\n",
    "        each thread is responsible for `thread_tile` number of elements\n",
    "     min_size: int\n",
    "         the minimum number of non-na elements\n",
    "    \"\"\"\n",
    "    shared = cuda.shared.array(shape=0,\n",
    "                               dtype=numba.float64)\n",
    "    block_size = cuda.blockDim.x  # total number of threads\n",
    "    tx = cuda.threadIdx.x\n",
    "    # Block id in a 1D grid\n",
    "    bid = cuda.blockIdx.x\n",
    "    starting_id = bid * block_size * thread_tile\n",
    "\n",
    "    # copy the thread_tile * number_of_thread_per_block into the shared\n",
    "    for j in range(thread_tile):\n",
    "        offset = tx + j * block_size\n",
    "        if (starting_id + offset) < arr_len:\n",
    "            shared[offset + window - 1] = in_arr[\n",
    "                starting_id + offset]\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    # copy the window - 1 into the shared\n",
    "    for j in range(0, window - 1, block_size):\n",
    "        if (((tx + j) <\n",
    "             window - 1) and (\n",
    "                 starting_id - window + 1 + tx + j >= 0)):\n",
    "            shared[tx + j] = \\\n",
    "                in_arr[starting_id - window + 1 + tx + j]\n",
    "        cuda.syncthreads()\n",
    "    # copy the weights into the shared\n",
    "    for j in range(0, window, block_size):\n",
    "        element_id = tx + j\n",
    "        if (((tx + j) < window) and (element_id < window)):\n",
    "            shared[thread_tile * block_size + window - 1 + tx +\n",
    "                   j] = weight_arr[tx + j]\n",
    "        cuda.syncthreads()\n",
    "    # slice the shared memory for each threads\n",
    "    start_shared = tx * thread_tile\n",
    "    his_len = min(window - 1,\n",
    "                  starting_id + tx * thread_tile)\n",
    "    # slice the global memory for each threads\n",
    "    start = starting_id + tx * thread_tile\n",
    "    end = min(starting_id + (tx + 1) * thread_tile, arr_len)\n",
    "    sub_outarr = out_arr[start:end]\n",
    "    sub_len = end - start\n",
    "    conv_window(shared, his_len, sub_outarr,\n",
    "                window, sub_len,\n",
    "                window - 1 + start_shared,\n",
    "                thread_tile * block_size + window - 1,\n",
    "                min_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fractional differencing is essentially doing 1D convolution computation with the kernel values set to be the weights computed from get_weights_floored. Check the original notebook for the details of the meanings of the weights. To make convolution computation faster, we divide the long input array into small chunks and send to different thread blocks. All the array chunks and the weights are loaded into the GPU shared memory for fast IO. The device function conv_window is doing the convolution computation for one thread.\n",
    "\n",
    "To make a fair comparsion with CPU implementation, we implemented an efficient CPU version of the fractional differencing calculation. It is accelerated by numba.njit that take advantage of multiple cores of the CPU and fastmath compiler optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True, parallel=True)\n",
    "def moving_dot_product_cpu(in_data, out, window_size, weights):\n",
    "    # Set the first window_size-1 rows in each chunk to np.nan due \n",
    "    # insufficient history\n",
    "    for i in prange(0, window_size - 1):\n",
    "        out[i] = np.nan\n",
    "    \n",
    "    # Compute dot product of preceding window_size rows\n",
    "    for i in prange(window_size - 1, len(in_data)):\n",
    "        rolling_dot_product = 0.0\n",
    "        \n",
    "        k = 0\n",
    "        for j in range(i - window_size + 1, i + 1):\n",
    "            rolling_dot_product += in_data[j] * weights[k]\n",
    "            k += 1\n",
    "        \n",
    "        out[i] = rolling_dot_product \n",
    "\n",
    "def cpu_fractional_diff(input_arr, d=0.5, floor=1e-3):\n",
    "\n",
    "    # compute the weights for the fractional difference\n",
    "    weights = get_weights_floored(d=d,\n",
    "                                  num_k=len(input_arr),\n",
    "                                  floor=floor)[::-1, 0]\n",
    "    weights_out = np.ascontiguousarray(weights)\n",
    "    weights = weights_out\n",
    "    weights_window_size = len(weights)\n",
    "    window = len(weights)\n",
    "    out = np.zeros_like(input_arr)\n",
    "    moving_dot_product_cpu(input_arr, out, weights_window_size, weights)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fractional differencing is essentially doing 1D convolution computation with the kernel values set to be the weights computed from `get_weights_floored`. Check the original [notebook](https://github.com/ritchieng/fractional_differencing_gpu/blob/master/notebooks/gpu_fractional_differencing.ipynb) for the details of the meanings of the weights. To make convolution computation faster, we divide the long input array into small chunks and send to different thread blocks. All the array chunks and the weights are loaded into the GPU shared memory for fast IO. The device function `conv_window` is doing the convolution computation for one thread.\n",
    "\n",
    "We can compare the performance of greenflow GPU implementation vs the original one and CPU implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array size 100000, Ensemble: time 0.356 s, greenflow GPU Time 0.351 s, greenflow CPU Time 0.493, speed up 1.01, speed up vs CPU 1.40, error 0.0000 \n",
      "array size 1000000, Ensemble: time 0.144 s, greenflow GPU Time 0.005 s, greenflow CPU Time 0.043, speed up 28.27, speed up vs CPU 8.55, error 0.0000 \n",
      "array size 10000000, Ensemble: time 1.143 s, greenflow GPU Time 0.016 s, greenflow CPU Time 0.342, speed up 70.96, speed up vs CPU 21.21, error 0.0000 \n",
      "array size 100000000, Ensemble: time 11.128 s, greenflow GPU Time 0.115 s, greenflow CPU Time 3.036, speed up 96.91, speed up vs CPU 26.44, error 0.0000 \n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 9):\n",
    "    df_raw = cudf.DataFrame()\n",
    "    ran_array = np.random.rand(10**int(i))\n",
    "    df_raw['in'] = ran_array\n",
    "    df_raw2 = cudf.DataFrame()\n",
    "    df_raw2['in'] = ran_array\n",
    "\n",
    "    # Start timer\n",
    "    start = time.time()\n",
    "    df_raw_fd_from_gpu, weights = frac_diff_gpu(df_raw, d=0.5, floor=5e-5)\n",
    "    # End timer\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "\n",
    "    start = time.time()\n",
    "    greenflow_gpu, weights = fractional_diff(df_raw2['in'], d=0.5, floor=5e-5)\n",
    "    cuda.synchronize()\n",
    "    end = time.time()\n",
    "    optimized_duration = end - start\n",
    "    #(df_raw_fd_from_gpu.values)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    cpu_result = cpu_fractional_diff(ran_array, d=0.5, floor=5e-5)\n",
    "    end = time.time()\n",
    "    cpu_duration = end - start\n",
    "    \n",
    "    err = np.abs(df_raw_fd_from_gpu['out'].to_array()[weights.size-1:] - np.array(greenflow_gpu)[weights.size-1:]).max()\n",
    "    err = max(np.abs(df_raw_fd_from_gpu['out'].to_array()[weights.size-1:] - cpu_result[weights.size-1:]).max(), err)\n",
    "    print('array size %d, Ensemble: time %.3f s, greenflow GPU Time %.3f s, greenflow CPU Time %.3f, speed up %.2f, speed up vs CPU %.2f, error %.4f ' % (10**int(i), duration, optimized_duration, cpu_duration, duration / optimized_duration, cpu_duration/optimized_duration, err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the array of length 100m, greenflow can achieve 100x speedup compare with the Ensemble Capitial's GPU implementatoin and 30x speed up compared with multiple core CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the fractional differencing signal to trade stocks\n",
    "\n",
    "We will use the same [XGBoost example](https://github.com/rapidsai/greenflow/blob/master/notebooks/06_xgboost_trade.ipynbx) to do backtest with fractional differencing signals. The workflow includes the following steps:\n",
    "\n",
    "1. Preprocess the datasets.\n",
    "\n",
    "2. Compute the features based on different fractional differencing signals of the closing prices of the stocks \n",
    "\n",
    "3. Split the data in training and testing and build a XGBoost model based on the training data. From the XGBoost model, compute the trading signals for all the data points.\n",
    "\n",
    "4. Run backtesting and compute the returns from this strategy for each of the days and stock symbols \n",
    "\n",
    "5. Run a simple portfolio optimization by averaging the stocks together for each of the trading days.\n",
    "\n",
    "6. Compute the Sharpe ratio and cumulative return results for both training and testing datasets\n",
    "\n",
    "The whole workflow can be organized into a computation graph, which are fully described in a yaml file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each nodes has a unique id, a node type, configuration parameters and input nodes ids. greenflow takes this yaml file, wires it into a graph to visualize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b11ec419ed84e389a8e97f070749220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GreenflowWidget(sub=HBox(), value=[OrderedDict([('id', 'stock_data'), ('type', 'CsvStockLoader'), ('conf', {'f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reset -s -f\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "import greenflow\n",
    "from greenflow.dataframe_flow import TaskGraph\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "task_graph = TaskGraph.load_taskgraph('../taskgraphs/xgboost_trade.gq.yaml')\n",
    "task_graph.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features used for XGBoost algorithm are prepared in the `xgboost` Task node, where `cuIndicator` module is used to compute the technical indicators in the GPU for all the stock symbols. `xgboost` is the Task node that is used to compute the trading signals from the stock technical indicators. Each of the greenflow Task node is implemented by overwriting `meta_setup`, `process`, `ports_setup`, `conf_chema` methods of the Node base class. Please refer to [customize nodes notebook](https://github.com/rapidsai/greenflow/blob/master/notebooks/05_customize_nodes.ipynb) for details. Following is the source code for \"XGBoostStrategyNode\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig2img(fig):\n",
    "    \"\"\"Convert a Matplotlib figure to BufferIO\"\"\"\n",
    "    import io\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    return buf\n",
    "\n",
    "# define the function to format the plots\n",
    "def plot_figures(o):\n",
    "\n",
    "    sharpe_number = o['sharpe_ratio_trn.sharpe_out']\n",
    "    cum_return_train = o['cumulative_return_trn.cum_return']\n",
    "    cum_return_train.set_figwidth(10)\n",
    "    cum_return_train.suptitle('Train P & L %.3f' % (sharpe_number), fontsize=16)\n",
    "    i = fig2img(cum_return_train)\n",
    "    img_train = widgets.Image(\n",
    "                        value=i.read(),\n",
    "                        format='png',\n",
    "                        width=600,\n",
    "                        height=900,\n",
    "    )\n",
    "    sharpe_number = o['sharpe_ratio_val.sharpe_out']\n",
    "    cum_return_test = o['cumulative_return_val.cum_return']\n",
    "    cum_return_test.set_figwidth(10)\n",
    "    cum_return_test.suptitle('Test P & L %.3f' % (sharpe_number), fontsize=16)\n",
    "    i = fig2img(cum_return_test)\n",
    "    img_test = widgets.Image(\n",
    "                        value=i.read(),\n",
    "                        format='png',\n",
    "                        width=600,\n",
    "                        height=900,\n",
    "    )\n",
    "    return widgets.VBox([img_train, img_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are going to add 5 fractional differencing signals from the closing prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_conf = {\n",
    "    \"indicators\": [\n",
    "        {\"function\": \"port_fractional_diff\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [0.5]\n",
    "        },\n",
    "        {\"function\": \"port_fractional_diff\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [0.3]\n",
    "        },\n",
    "        {\"function\": \"port_fractional_diff\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [0.1]\n",
    "        },\n",
    "        {\"function\": \"port_fractional_diff\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [0.7]\n",
    "        },\n",
    "        {\"function\": \"port_fractional_diff\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [0.9]\n",
    "        },\n",
    "        {\"function\": \"port_shift\",\n",
    "         \"columns\": [\"returns\"],\n",
    "         \"args\": [-1]\n",
    "        }        \n",
    "    ],\n",
    "    \"remove_na\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:stock_data process time:3.321s\n",
      "id:preprocess process time:0.873s\n",
      "id:sort_after process time:0.067s\n",
      "id:technical_indicator process time:0.448s\n",
      "id:train_df process time:0.129s\n",
      "id:validation_df process time:0.010s\n",
      "id:persist process time:0.004s\n",
      "id:xboost_model process time:1.761s\n",
      "id:train_infer process time:0.154s\n",
      "id:train_signal process time:0.022s\n",
      "id:train_backtest process time:0.001s\n",
      "id:portfolio_opt_train process time:0.010s\n",
      "id:sharpe_ratio_trn process time:0.001s\n",
      "id:cumulative_return_trn process time:0.020s\n",
      "id:val_infer process time:0.110s\n",
      "id:val_signal process time:0.017s\n",
      "id:val_backtest process time:0.001s\n",
      "id:portfolio_opt_validation process time:0.010s\n",
      "id:sharpe_ratio_val process time:0.001s\n",
      "id:cumulative_return_val process time:0.019s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3996c18c67a4469ea2c872d6f554d337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\xd0\\x00\\x00\\x01 \\x08\\x06\\x00\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "replace_spec = {}\n",
    "replace_spec['technical_indicator'] = {\"conf\": indicator_conf}\n",
    "\n",
    "o_gpu = task_graph.run(replace=replace_spec, profile=True)\n",
    "\n",
    "plot_figures(o_gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get Sharpe Ratio of `1.01` just from the fractional differencing signals of the closing prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the computed fractional differencing signals, we can make a TaskGraph to visualize it. We put the XGboost trade TaskGraph into a composite node. We select the asset with id `22123` and plot 4 fractional differencing signals with different `d` values. Check the updated graph below. Note, there are 2 layers of composite nodes in the following graph. As you can see, composite node is a powerful way of organizing the TaskGraphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ca99978e554f6fb8c9b818dec95d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GreenflowWidget(sub=HBox(), value=[OrderedDict([('id', 'stock_data'), ('type', 'CsvStockLoader'), ('conf', {'f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_graph = TaskGraph.load_taskgraph('../taskgraphs/visualize_frac_diff.gq.yaml')\n",
    "task_graph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5f1b2e20624e9baa1daf2129dbf845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(layout=Layout(border='1px solid black'), outputs=({'output_type': 'stream', 'na…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_graph.run(formated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the sub-graph just for plotting the signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, smaller `d` value signal has more memory information but not as stationary as the high `d` value signals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "In this notebook, we demoed how to use Numba to implemement fractional differencing calculation in GPU. It achieves 100x speed up compared with the method done by Ensemble Capital. We also showed it is easy to use greenflow to compute fractional difference and run backtests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
