{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade with XGBoost algorithm\n",
    "## Background\n",
    "In the [portfolio trade example](https://github.com/rapidsai/greenflow/blob/master/notebooks/04_portfolio_trade.ipynb), we use greenflow to backtest a simple mean reversion trading strategy on 5000 stocks.\n",
    "It shows decent performance by tweaking the moving average window size. Searching for alpha signal is the ultimate goal for the trading companies. A lot of different methods are used to do so. Machine learning approach\n",
    "is one of those. It has the benefits of extracting important information in the data automatically given enough computation. There are a few popular machine learning algrithoms, including SVM, Random forest tree etc. Amoung those, XGBoost is known to be a very powerful machine \n",
    "learning method that is winning a lot of [ML competitions](https://medium.com/syncedreview/tree-boosting-with-xgboost-why-does-xgboost-win-every-machine-learning-competition-ca8034c0b283). Luckily, the [RAPIDS library](https://github.com/rapidsai) accelerates the XGBoost ML algorithm in the GPU so that we can easily take advantage of it in the greenflow. \n",
    "\n",
    "In this notebook, we are going to demo how to use greenflow to backtest a XGBoost based trading stragty.\n",
    "\n",
    "\n",
    "## Environment Preparation\n",
    "\n",
    "### Download the example Datasets\n",
    "Before getting started, let's download the example datasets if not presen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already present. No need to re-download it.\n"
     ]
    }
   ],
   "source": [
    "! ((test ! -f './data/stock_price_hist.csv.gz' ||  test ! -f './data/security_master.csv.gz') && \\\n",
    "  cd .. && bash download_data.sh) || echo \"Dataset is already present. No need to re-download it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for running in Dask environment\n",
    "\n",
    "Let's start the Dask local cluster environment for distributed computation.\n",
    "\n",
    "Dask provides a web-based dashboard to help to track progress, identify performance issues, and debug failures. To learn more about Dask dashboard, just follow this [link](https://distributed.dask.org/en/latest/web.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yidong/miniconda3/envs/work18/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37461 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:35411</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:37461/status' target='_blank'>http://127.0.0.1:37461/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>270.39 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:35411' processes=4 threads=4, memory=270.39 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the Dask local cluster environment for distrubuted computation\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though our stock dataset is small enough to fit in a single 16G GPU, to show how to do distributed computation, we will split the dataframe into small pieces to be loaded by different workers in the cluster.\n",
    "\n",
    "Notice this step is need only if the dataset is not split in multiple files yet.\n",
    "\n",
    "First use this simple taskgraph to load data then sort it by the asset id and datatime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e1bd2a639842a788555e68341a832f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GreenflowWidget(sub=HBox(), value=[OrderedDict([('id', 'stock_data'), ('type', 'CsvStockLoader'), ('conf', {'f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import warnings\n",
    "from greenflow.dataframe_flow import TaskGraph\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "warnings.simplefilter(\"ignore\")\n",
    "task_graph = TaskGraph.load_taskgraph('../taskgraphs/sort_stocks.gq.yaml')\n",
    "input_cached, = task_graph.run()\n",
    "task_graph.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the sorted stock data into partitions and save it into csv files. Note, the data is slited in a way that the same asset belongs to the same partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/yidong/Projects/gQuant/gQuant/plugins/gquant_plugin/notebooks/many-small/0.csv',\n",
       " '/home/yidong/Projects/gQuant/gQuant/plugins/gquant_plugin/notebooks/many-small/1.csv',\n",
       " '/home/yidong/Projects/gQuant/gQuant/plugins/gquant_plugin/notebooks/many-small/2.csv',\n",
       " '/home/yidong/Projects/gQuant/gQuant/plugins/gquant_plugin/notebooks/many-small/3.csv',\n",
       " '/home/yidong/Projects/gQuant/gQuant/plugins/gquant_plugin/notebooks/many-small/4.csv',\n",
       " '/home/yidong/Projects/gQuant/gQuant/plugins/gquant_plugin/notebooks/many-small/5.csv',\n",
       " '/home/yidong/Projects/gQuant/gQuant/plugins/gquant_plugin/notebooks/many-small/6.csv',\n",
       " '/home/yidong/Projects/gQuant/gQuant/plugins/gquant_plugin/notebooks/many-small/7.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "num_partitions = 8\n",
    "\n",
    "dd.from_pandas(input_cached, npartitions=num_partitions).shuffle(on=['asset']).to_csv('many-small/*.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this notebook requires `cudf` of version >=0.8.0. It can be checked by following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.0\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "print(cudf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The toy example\n",
    "To mimic the end-to-end quantitative analyst task, we are going to backtest a XGBoost trading strategy. \n",
    "\n",
    "We will reuse the preprocessing steps as shown in the portfolio trade notebook example. \n",
    "\n",
    "The workflow includes following steps:\n",
    "\n",
    "1. Preprocess the datasets.\n",
    "\n",
    "4. Compute the features based on different technical indicators \n",
    "\n",
    "5. Split the data in training and testing and build a XGBoost model based on the training data. From the XGBoost model, compute the trading signals for all the data points.\n",
    "\n",
    "5. Run backtesting and compute the returns from this strategy for each of the days and stock symbols \n",
    "\n",
    "6. Run a simple portfolio optimization by averaging the stocks together for each of the trading days.\n",
    "\n",
    "7. Compute the sharpe ratio and cumulative return results for both training and testing datasets\n",
    "\n",
    "The whole workflow can be organized into a TaskGraph, which are fully described in a `.gq.yaml` file.\n",
    "\n",
    "Each nodes has a unique id, a node type, configuration parameters and input nodes ids. greenflow takes this yaml file, wires it into a graph to visualize it.\n",
    "\n",
    "First let's load the proprocess TaskGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4980703bb384895853177f78ba8095c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GreenflowWidget(sub=HBox(), value=[OrderedDict([('id', 'stock_data'), ('type', 'CsvStockLoader'), ('conf', {'f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_graph = TaskGraph.load_taskgraph('../taskgraphs/preprocess.gq.yaml')\n",
    "task_graph.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lode the whole TaskGraph by `load_taskgraph` command. Note the preprocess TaskGraph is included inside the `preprocess` `Composite Node`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5faa2d5475346c5893b798722493844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GreenflowWidget(sub=HBox(), value=[OrderedDict([('id', 'stock_data'), ('type', 'CsvStockLoader'), ('conf', {'f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_graph = TaskGraph.load_taskgraph('../taskgraphs/xgboost_trade.gq.yaml')\n",
    "task_graph.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features used for XGBoost algorithm are prepared in the `xgboost` Task node, where `cuIndicator` module is used to compute the technical indicators in the GPU for all the stock symbols. `xgboost` is the Task node that is used to compute the trading signals from the stock technical indicators. Each of the greenflow Task node is implemented by overwriting `meta_setup`, `process`, `ports_setup`, `conf_chema` methods of the Node base class. Please refer to [customize nodes notebook](https://github.com/rapidsai/greenflow/blob/master/notebooks/05_customize_nodes.ipynb) for details. Following is the source code for \"XGBoostStrategyNode\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class XGBoostStrategyNode(_PortTypesMixin, Node):\n",
      "    \"\"\"\n",
      "    This is the Node used to compute trading signal from XGBoost Strategy.\n",
      "    It requires the following conf fields:\n",
      "        \"train_date\": a date string of \"Y-m-d\" format. All the data points\n",
      "        before this date is considered as training, otherwise as testing. If\n",
      "        not provided, all the data points are considered as training.\n",
      "        \"xgboost_parameters\": a dictionary of any legal parameters for XGBoost\n",
      "        models. It overwrites the default parameters used in the process method\n",
      "        \"no_feature\": specifying a list of columns in the input dataframe that\n",
      "        should NOT be considered as training features.\n",
      "        \"target\": the column that is considered as \"target\" in machine learning\n",
      "        algorithm\n",
      "    It requires the \"datetime\" column for spliting the data points and adds a\n",
      "    new column \"signal\" to be used for backtesting.\n",
      "    The detailed computation steps are listed in the process method's docstring\n",
      "    \"\"\"\n",
      "\n",
      "    def init(self):\n",
      "        _PortTypesMixin.init(self)\n",
      "        self.INPUT_PORT_NAME = 'stock_in'\n",
      "        self.OUTPUT_PORT_NAME = 'stock_out'\n",
      "\n",
      "    def meta_setup(self):\n",
      "        # if 'no_feature' in self.conf:\n",
      "        #     retention = self.conf['no_feature']\n",
      "        # else:\n",
      "        cols_required = {'datetime': 'date',\n",
      "                         \"asset\": \"int64\"}\n",
      "        # self.delayed_process = True\n",
      "        required = {\n",
      "            self.INPUT_PORT_NAME: cols_required\n",
      "        }\n",
      "        retention = {}\n",
      "        retention['signal'] = 'float64'\n",
      "        # _PortTypesMixin.retention_meta_setup(self, retention)\n",
      "\n",
      "        input_meta = self.get_input_meta()\n",
      "        if self.INPUT_PORT_NAME not in input_meta:\n",
      "            col_from_inport = required[self.INPUT_PORT_NAME]\n",
      "        else:\n",
      "            col_from_inport = input_meta[self.INPUT_PORT_NAME]\n",
      "        # delete the columns from the inputs\n",
      "        if 'no_feature' in self.conf:\n",
      "            for key in self.conf['no_feature']:\n",
      "                if key in col_from_inport:\n",
      "                    retention[key] = col_from_inport[key]\n",
      "        metadata = MetaData(inports=required,\n",
      "                            outports={self.OUTPUT_PORT_NAME: retention})\n",
      "        return metadata\n",
      "\n",
      "    def ports_setup(self):\n",
      "        types = [cudf.DataFrame,\n",
      "                 dask_cudf.DataFrame]\n",
      "        return _PortTypesMixin.ports_setup_from_types(self, types)\n",
      "\n",
      "    def conf_schema(self):\n",
      "        json = {\n",
      "            \"title\": \"XGBoost Node configure\",\n",
      "            \"type\": \"object\",\n",
      "            \"description\": \"\"\"Split the data into training and testing based on\n",
      "             'train_data', train a XGBoost model based on the training data,\n",
      "             make predictions for all the data points, compute the trading.\n",
      "            \"\"\",\n",
      "            \"properties\": {\n",
      "                \"num_of_rounds\": {\n",
      "                    \"type\": \"number\",\n",
      "                    \"description\": \"\"\"The number of rounds for boosting\"\"\",\n",
      "                    \"default\": 100\n",
      "                },\n",
      "                \"train_date\":  {\n",
      "                    \"type\": \"string\",\n",
      "                    \"description\": \"\"\"the date to splite train and validation\n",
      "                    dataset\"\"\"\n",
      "                },\n",
      "                \"target\":  {\n",
      "                    \"type\": \"string\",\n",
      "                    \"description\": \"the column used as dependent variable\"\n",
      "                },\n",
      "                \"no_feature\": {\n",
      "                    \"type\": \"array\",\n",
      "                    \"items\": {\n",
      "                        \"type\": \"string\",\n",
      "                    },\n",
      "                    \"description\": \"\"\"columns in the input dataframe that\n",
      "        should NOT be considered as training features.\"\"\"\n",
      "                },\n",
      "                \"xgboost_parameters\": {\n",
      "                    \"type\": \"object\",\n",
      "                    \"description\": \"xgoobst parameters\",\n",
      "                    \"properties\": {\n",
      "                        'max_depth': {\n",
      "                            \"type\": \"number\",\n",
      "                            \"description\": \"Maximum depth of a tree.\",\n",
      "                            \"default\": 8\n",
      "                        },\n",
      "                        \"max_leaves\": {\n",
      "                            \"type\": \"number\",\n",
      "                            \"description\": \"maximum number of tree leaves\",\n",
      "                            \"default\": 2**8\n",
      "                        },\n",
      "                        \"gamma\": {\n",
      "                            \"type\": \"number\",\n",
      "                            \"description\": \"\"\"Minimum loss reduction required\n",
      "                            to make a further partition on a leaf node of the\n",
      "                            tree.\"\"\",\n",
      "                            \"default\": 0\n",
      "                        },\n",
      "                        \"objective\": {\n",
      "                            \"type\": \"string\",\n",
      "                            \"enum\": [\"reg:squarederror\", \"reg:squaredlogerror\",\n",
      "                                     \"reg:logistic\", \"reg:pseudohubererror\"],\n",
      "                            \"description\": \"\"\"Specify the learning task and\n",
      "                            the corresponding learning objective.\"\"\",\n",
      "                            \"default\": \"reg:squarederror\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\"target\", \"num_of_rounds\"],\n",
      "        }\n",
      "        ui = {\n",
      "            \"train_date\":  {\n",
      "                \"ui:widget\": \"alt-date\",\n",
      "                \"ui:options\": {\n",
      "                        \"yearsRange\": [1985, 2025],\n",
      "                        \"hideNowButton\": True,\n",
      "                        \"hideClearButton\": True,\n",
      "                },\n",
      "            },\n",
      "        }\n",
      "        input_meta = self.get_input_meta()\n",
      "        if self.INPUT_PORT_NAME in input_meta:\n",
      "            col_from_inport = input_meta[self.INPUT_PORT_NAME]\n",
      "            enums = [col for col in col_from_inport.keys()]\n",
      "            json['properties']['no_feature']['items']['enum'] = enums\n",
      "            json['properties']['target']['enum'] = enums\n",
      "            return ConfSchema(json=json, ui=ui)\n",
      "        else:\n",
      "            return ConfSchema(json=json, ui=ui)\n",
      "\n",
      "    def process(self, inputs):\n",
      "        \"\"\"\n",
      "        The process is doing following things:\n",
      "            1. split the data into training and testing based on provided\n",
      "               conf['train_date']. If it is not provided, all the data is\n",
      "               treated as training data.\n",
      "            2. train a XGBoost model based on the training data\n",
      "            3. Make predictions for all the data points including training and\n",
      "               testing.\n",
      "            4. From the prediction of returns, compute the trading signals that\n",
      "               can be used in the backtesting.\n",
      "        Arguments\n",
      "        -------\n",
      "         inputs: list\n",
      "            list of input dataframes.\n",
      "        Returns\n",
      "        -------\n",
      "        dataframe\n",
      "        \"\"\"\n",
      "        dxgb_params = {\n",
      "                'max_depth':         8,\n",
      "                'max_leaves':        2 ** 8,\n",
      "                'tree_method':       'gpu_hist',\n",
      "                'objective':         'reg:squarederror',\n",
      "                'grow_policy':       'lossguide',\n",
      "        }\n",
      "        # num_of_rounds = 100\n",
      "        if 'xgboost_parameters' in self.conf:\n",
      "            dxgb_params.update(self.conf['xgboost_parameters'])\n",
      "        input_df = inputs[self.INPUT_PORT_NAME]\n",
      "        model_df = input_df\n",
      "        train_cols = set(model_df.columns) - set(\n",
      "            self.conf['no_feature'])\n",
      "        train_cols = list(train_cols - set([self.conf['target']]))\n",
      "\n",
      "        if isinstance(input_df, dask_cudf.DataFrame):\n",
      "            # get the client\n",
      "            client = dask.distributed.client.default_client()\n",
      "            if 'train_date' in self.conf:\n",
      "                train_date = datetime.datetime.strptime(self.conf['train_date'],  # noqa: F841, E501\n",
      "                                                        '%Y-%m-%d')\n",
      "                model_df = model_df[model_df.datetime < train_date]\n",
      "            train = model_df[train_cols]\n",
      "            target = model_df[self.conf['target']]\n",
      "            dmatrix = xgb.dask.DaskDMatrix(client, train, label=target)\n",
      "            bst = xgb.dask.train(client, dxgb_params, dmatrix,\n",
      "                                 num_boost_round=self.conf[\"num_of_rounds\"])\n",
      "\n",
      "            dtrain = xgb.dask.DaskDMatrix(client, input_df[train_cols])\n",
      "            prediction = xgb.dask.predict(client, bst, dtrain).persist()\n",
      "            pred_df = dask_cudf.from_dask_dataframe(\n",
      "                prediction.to_dask_dataframe())\n",
      "            pred_df.index = input_df.index\n",
      "            input_df['signal'] = pred_df\n",
      "        elif isinstance(input_df, cudf.DataFrame):\n",
      "            if 'train_date' in self.conf:\n",
      "                train_date = datetime.datetime.strptime(self.conf['train_date'],  # noqa: F841, E501\n",
      "                                                        '%Y-%m-%d')\n",
      "                model_df = model_df.query('datetime<@train_date')\n",
      "            train = model_df[train_cols]\n",
      "            target = model_df[self.conf['target']]\n",
      "            dmatrix = xgb.DMatrix(train, label=target)\n",
      "            bst = xgb.train(dxgb_params, dmatrix,\n",
      "                            num_boost_round=self.conf[\"num_of_rounds\"])\n",
      "            infer_dmatrix = xgb.DMatrix(input_df[train_cols])\n",
      "            prediction = cudf.Series(bst.predict(infer_dmatrix),\n",
      "                                     nan_as_null=False,\n",
      "                                     index=input_df.index\n",
      "                                     ).astype('float64')\n",
      "            input_df['signal'] = prediction\n",
      "\n",
      "        input_df['tmp'] = (input_df['asset'] -\n",
      "                           input_df['asset'].shift(1)).fillna(1)\n",
      "        input_df['tmp'] = (input_df['tmp'] != 0).astype('int32')\n",
      "        tmp = input_df['tmp']\n",
      "        input_df['tmp'] = tmp.where(tmp != 1, None)\n",
      "        input_df = input_df.dropna(subset=['tmp'])\n",
      "        input_df = input_df.drop('tmp', axis=1)\n",
      "\n",
      "        # convert the signal to trading action\n",
      "        # 1 is buy and -1 is sell\n",
      "        # It predicts the tomorrow's return (shift -1)\n",
      "        # We shift 1 for trading actions so that it acts on the second day\n",
      "        input_df['signal'] = ((\n",
      "            input_df['signal'] >= 0).astype('float') * 2 - 1).shift(1)\n",
      "\n",
      "        # remove the bad datapints\n",
      "        input_df = input_df.dropna()\n",
      "        remaining = list(self.conf['no_feature']) + ['signal']\n",
      "        return {self.OUTPUT_PORT_NAME: input_df[remaining]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from greenflow_gquant_plugin.strategy import XGBoostStrategyNode\n",
    "\n",
    "print(inspect.getsource(XGBoostStrategyNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Trading Strategy Performance\n",
    "Similar to tensorflow, greenflow graph is evaluated by specifying the output nodes and input nodes replacement. We first look at the column result from data preparation node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output meta of node node_technical_indicator:\n",
      "MetaData(inports={'stock_in': {'indicator': 'int32', 'high': 'float64', 'low': 'float64', 'close': 'float64', 'volume': 'float64', 'returns': 'float64'}}, outports={'stock_out': {'CH_OS_10_20': 'float64', 'BO_BA_b1_10': 'float64', 'BO_BA_b2_10': 'float64', 'SHIFT_-1': 'float64', 'indicator': 'int32', 'returns': 'float64', 'datetime': 'date', 'asset': 'int64', 'volume': 'float64', 'close': 'float64', 'open': 'float64', 'high': 'float64', 'low': 'float64'}})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print('output meta of node node_technical_indicator:')\n",
    "task_graph.build()\n",
    "pprint(task_graph['technical_indicator'].meta_setup())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It adds the columns \"BO_BA_b1_10\", \"BO_BA_b2_10\", 'CH_OS_10_20\" as features and \"SHFIT_-1\" as the target, which is the return of next day. A good feature should be the one that provides highest information about the next day return. In the case we have no prior information about it,\n",
    "we can compute as many features as we like and leave it to the XGBoost to find the right combination of those features. \n",
    "\n",
    "Evaluate the leaf nodes of the backtesting graph by greenflow `run` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:stock_data process time:4.270s\n",
      "id:preprocess process time:0.761s\n",
      "id:sort_after process time:0.056s\n",
      "id:technical_indicator process time:2.571s\n",
      "id:xgboost process time:2.495s\n",
      "id:backtest process time:0.001s\n",
      "id:train_df process time:0.125s\n",
      "id:portfolio_opt_train process time:0.012s\n",
      "id:sharpe_ratio_trn process time:0.001s\n",
      "id:cumulative_return_trn process time:0.016s\n",
      "id:validation_df process time:0.006s\n",
      "id:portfolio_opt_validation process time:0.009s\n",
      "id:sharpe_ratio_val process time:0.001s\n",
      "id:cumulative_return_val process time:0.015s\n",
      "CPU times: user 10 s, sys: 1.43 s, total: 11.4 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output_list = ['sharpe_ratio_trn.sharpe_out',\n",
    "               'cumulative_return_trn.cum_return',\n",
    "               'sharpe_ratio_val.sharpe_out',\n",
    "               'cumulative_return_val.cum_return',\n",
    "               'sort_after.out']\n",
    "o_gpu = task_graph.run(output_list, profile=True)\n",
    "cached_sort = o_gpu['sort_after.out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to organized the plot results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ac1d90b02b407b9a9df08658f437b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(label='Cumulative return', orientation='vertical', scale=LinearScale(), side=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the function to format the plots\n",
    "def plot_figures(o):\n",
    "    # format the figures\n",
    "    figure_width = '1200px'\n",
    "    figure_height = '400px'\n",
    "    sharpe_number = o['sharpe_ratio_trn.sharpe_out']\n",
    "    cum_return_train = o['cumulative_return_trn.cum_return']\n",
    "    cum_return_train.layout.height = figure_height\n",
    "    cum_return_train.layout.width = figure_width\n",
    "    cum_return_train.title = 'Training P & L %.3f' % (sharpe_number)\n",
    "    sharpe_number = o['sharpe_ratio_val.sharpe_out']\n",
    "    cum_return_test = o['cumulative_return_val.cum_return']\n",
    "    cum_return_test.layout.height = figure_height\n",
    "    cum_return_test.layout.width = figure_width\n",
    "    cum_return_test.title = 'Testing P & L %.3f' % (sharpe_number)\n",
    "\n",
    "    return widgets.VBox([cum_return_train, cum_return_test])\n",
    "plot_figures(o_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model does a good job to predict the next day of return. It overfits in the training dataset and gets Sharpe Ratio of 5 as shown in the figure above. In the testing period, it gets Sharpe Ratio of 1.\n",
    "\n",
    "The example model runs in a single GPU because of the small dataset. But in real world, the dataset usually is so large that it doesn't fit in a single GPU. Luckily, the XGBoost library natively supports multiple nodes and multiple GPU training by using Dask. You can scale out the computation using Dask dataframe.\n",
    "\n",
    "To show how easy it is to do distributed computation, let's run the above exmaple in the Dask environment for educational purpose.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the whole workflow, simply change the `preprocess` node to get Dask Dataframe and run the graph again. Here we look at the testing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:stock_data process time:0.010s\n",
      "id:preprocess process time:7.655s\n",
      "id:xgboost process time:3.325s\n",
      "id:backtest process time:0.010s\n",
      "id:train_df process time:0.143s\n",
      "id:portfolio_opt_train process time:0.033s\n",
      "id:sharpe_ratio_trn process time:1.407s\n",
      "id:cumulative_return_trn process time:1.193s\n",
      "id:validation_df process time:0.007s\n",
      "id:portfolio_opt_validation process time:0.032s\n",
      "id:sharpe_ratio_val process time:1.172s\n",
      "id:cumulative_return_val process time:1.268s\n",
      "CPU times: user 8.24 s, sys: 801 ms, total: 9.04 s\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "replace_spec = {'preprocess': {\"inputs\": {\"sort_node@in\": \"stock_data.dask_cudf_out\"}}}\n",
    "o_gpu = task_graph.run(replace=replace_spec, profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b03eaa90714b2381a5563914964296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(label='Cumulative return', orientation='vertical', scale=LinearScale(), side=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_figures(o_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Clearly, 3 feautres is way too little here. greenflow implmented 36 technical indicators. We can change the configuration of node_technical_indicator node to include more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaikin_para0 = 10\n",
    "chaikin_para1 = 20\n",
    "bollinger_para = 10\n",
    "macd_para0 = 2\n",
    "macd_para1 = 3\n",
    "rsi_para0 = 5\n",
    "atr_para0 = 10\n",
    "sod_para = 2\n",
    "mflow_para = 3\n",
    "findex_para = 5\n",
    "adis_para = 5\n",
    "ccindex_para = 5\n",
    "bvol_para = 3\n",
    "vindex_para = 3\n",
    "mindex_para0 = 10\n",
    "mindex_para1 = 15\n",
    "tindex_para0 = 5\n",
    "tindex_para1 = 10\n",
    "emove_para = 5\n",
    "cc_para = 15\n",
    "kchannel_para = 10\n",
    "indicator_conf = {\n",
    "    \"indicators\": [\n",
    "        {\"function\": \"port_chaikin_oscillator\",\n",
    "         \"columns\": [\"high\", \"low\", \"close\", \"volume\"],\n",
    "         \"args\": [chaikin_para0, chaikin_para1]\n",
    "        },\n",
    "        {\"function\": \"port_bollinger_bands\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [bollinger_para],\n",
    "         \"outputs\": [\"b1\", \"b2\"]\n",
    "        },\n",
    "        {\"function\": \"port_macd\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [macd_para0, macd_para1],\n",
    "         \"outputs\": [\"MACDsign\", \"MACDdiff\"]\n",
    "        },\n",
    "        {\"function\": \"port_relative_strength_index\",\n",
    "         \"columns\": [\"high\", \"low\"],\n",
    "         \"args\": [rsi_para0],\n",
    "        },\n",
    "        {\"function\": \"port_average_true_range\",\n",
    "         \"columns\": [\"high\", \"low\", \"close\"],\n",
    "         \"args\": [atr_para0],\n",
    "        },\n",
    "        {\"function\": \"port_stochastic_oscillator_k\",\n",
    "         \"columns\": [\"high\", \"low\", \"close\"],\n",
    "         \"args\": [],\n",
    "        },\n",
    "        {\"function\": \"port_stochastic_oscillator_d\",\n",
    "         \"columns\": [\"high\", \"low\", \"close\"],\n",
    "         \"args\": [sod_para],\n",
    "        },\n",
    "        {\"function\": \"port_money_flow_index\",\n",
    "         \"columns\": [\"high\", \"low\", \"close\", \"volume\"],\n",
    "         \"args\": [mflow_para],\n",
    "        },\n",
    "        {\"function\": \"port_force_index\",\n",
    "         \"columns\": [\"close\", \"volume\"],\n",
    "         \"args\": [findex_para],\n",
    "        },\n",
    "        {\"function\": \"port_ultimate_oscillator\",\n",
    "         \"columns\": [\"high\",\"low\",\"close\"],\n",
    "         \"args\": [],\n",
    "        },\n",
    "        {\"function\": \"port_accumulation_distribution\",\n",
    "         \"columns\": [\"high\",\"low\",\"close\",\"volume\"],\n",
    "         \"args\": [adis_para],\n",
    "        },\n",
    "        {\"function\": \"port_commodity_channel_index\",\n",
    "         \"columns\": [\"high\",\"low\",\"close\"],\n",
    "         \"args\": [ccindex_para],\n",
    "        },\n",
    "        {\"function\": \"port_on_balance_volume\",\n",
    "         \"columns\": [\"close\", \"volume\"],\n",
    "         \"args\": [bvol_para],\n",
    "        },\n",
    "        {\"function\": \"port_vortex_indicator\",\n",
    "         \"columns\": [\"high\", \"low\", \"close\"],\n",
    "         \"args\": [vindex_para],\n",
    "        },\n",
    "         {\"function\": \"port_kst_oscillator\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        },\n",
    "        {\"function\": \"port_mass_index\",\n",
    "         \"columns\": [\"high\", \"low\"],\n",
    "         \"args\": [mindex_para0, mindex_para1],\n",
    "        },\n",
    "        {\"function\": \"port_true_strength_index\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [tindex_para0, tindex_para1],\n",
    "        },\n",
    "        {\"function\": \"port_ease_of_movement\",\n",
    "         \"columns\": [\"high\", \"low\", \"volume\"],\n",
    "         \"args\": [emove_para],\n",
    "        },\n",
    "        {\"function\": \"port_coppock_curve\",\n",
    "         \"columns\": [\"close\"],\n",
    "         \"args\": [cc_para],\n",
    "        },\n",
    "        {\"function\": \"port_keltner_channel\",\n",
    "         \"columns\": [\"high\", \"low\", \"close\"],\n",
    "         \"args\": [kchannel_para],\n",
    "         \"outputs\": [\"KelChD\", \"KelChM\", \"KelChU\"]\n",
    "        },\n",
    "        {\"function\": \"port_ppsr\",\n",
    "         \"columns\": [\"high\", \"low\", \"close\"],\n",
    "         \"args\": [],\n",
    "         \"outputs\": [\"PP\", \"R1\", \"S1\", \"R2\", \"S2\", \"R3\", \"S3\"]\n",
    "        },\n",
    "        {\"function\": \"port_shift\",\n",
    "         \"columns\": [\"returns\"],\n",
    "         \"args\": [-1]\n",
    "        }        \n",
    "    ],\n",
    "    \"remove_na\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e4668f4fdf4a5cb7656b4fe42b7fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GreenflowWidget(cache={'nodes': [{'width': 140, 'id': 'stock_data', 'type': 'CsvStockLoader', 'schema': {'title':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_graph.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the backtesting again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:technical_indicator process time:2.659s\n",
      "id:xgboost process time:5.527s\n",
      "id:backtest process time:0.002s\n",
      "id:train_df process time:0.007s\n",
      "id:portfolio_opt_train process time:0.011s\n",
      "id:sharpe_ratio_trn process time:0.001s\n",
      "id:cumulative_return_trn process time:0.015s\n",
      "id:validation_df process time:0.005s\n",
      "id:portfolio_opt_validation process time:0.009s\n",
      "id:sharpe_ratio_val process time:0.001s\n",
      "id:cumulative_return_val process time:0.015s\n",
      "CPU times: user 7.86 s, sys: 1.37 s, total: 9.22 s\n",
      "Wall time: 8.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replace_spec = {}\n",
    "replace_spec['technical_indicator'] = {\"conf\": indicator_conf}\n",
    "\n",
    "replace_spec['sort_after'] = {\"load\": {'out': cached_sort}}\n",
    "\n",
    "o_gpu = task_graph.run(replace=replace_spec, profile=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37ca8d7dc8a487fbe99d187748ecb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(label='Cumulative return', orientation='vertical', scale=LinearScale(), side=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_figures(o_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get Sharpe Ratio of `1.93` in the testing dataset, not bad!\n",
    "\n",
    "Using `min_volume=400.0`, it selects 1558 stocks. Setting a lower threshhold, it can include more stocks for the backtesting and hence increase the Sharpe Ratio. But it runs out of memory of single GPU. We have shown Dask can help to break down the large task into small tasks and schedule them a distributed environment. So we can handle dataset of any sizes in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:stock_data process time:0.007s\n",
      "id:preprocess process time:5.938s\n",
      "id:xgboost process time:9.109s\n",
      "id:backtest process time:0.010s\n",
      "id:train_df process time:0.007s\n",
      "id:portfolio_opt_train process time:0.032s\n",
      "id:sharpe_ratio_trn process time:2.444s\n",
      "id:cumulative_return_trn process time:2.464s\n",
      "id:validation_df process time:0.006s\n",
      "id:portfolio_opt_validation process time:0.032s\n",
      "id:sharpe_ratio_val process time:2.344s\n",
      "id:cumulative_return_val process time:2.389s\n",
      "CPU times: user 10 s, sys: 2.84 s, total: 12.9 s\n",
      "Wall time: 43.4 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f37ade2840b4a6db394f4c07f5bca47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(label='Cumulative return', orientation='vertical', scale=LinearScale()), Axis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "min_volume = 4.0\n",
    "min_rate = -10.0\n",
    "max_rate = 10.0\n",
    "replace_spec={}\n",
    "replace_spec['technical_indicator'] = {\"conf\": indicator_conf}\n",
    "\n",
    "replace_spec['node_filterValue']={\"conf\": [{\"column\": \"volume_mean\", \"min\": min_volume},\n",
    "                                            {\"column\": \"returns_max\", \"max\": max_rate},\n",
    "                                            {\"column\": \"returns_min\", \"min\": min_rate}]}\n",
    "replace_spec['preprocess'] = {\"conf\": {\"subnodes_conf\": {\n",
    "                                            \"value_filter\": {\n",
    "                                                \"conf\": [{\"column\": \"average_volume\", \"min\": min_volume},\n",
    "                                                         {\"column\": \"max_return\", \"max\": max_rate},\n",
    "                                                         {\"column\": \"min_return\", \"min\": min_rate}]\n",
    "                                            },\n",
    "                                            \"drop_columns\": {\n",
    "                                                \"conf\": {\n",
    "                                                    \"columns\": [\"average_volume\", \"min_return\", \"max_return\"]\n",
    "                                                }\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"taskgraph\": \"taskgraphs/preprocess.gq.yaml\",\n",
    "                                        \"input\": [\"sort_node.in\"],\n",
    "                                        \"output\": [\"drop_columns.out\"]\n",
    "                                    },\n",
    "                              \"inputs\": {\"sort_node@in\": \"stock_data.dask_cudf_out\"}}\n",
    "\n",
    "o_gpu = task_graph.run(replace=replace_spec, profile=True)\n",
    "plot_figures(o_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd477080878b49c28174a3c3b1218369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(label='Cumulative return', orientation='vertical', scale=LinearScale()), Axis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_figures(o_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get Sharpe Ratio of `4.7` in the testing dataset. This is a great improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy parameter search\n",
    "Quantitative analyst usually need to explore different parameters for their trading strategy. The exploration process is an iterative process. greenflow help to speed up this by allowing using cached dataframe and evaluating the sub-graphs.\n",
    "\n",
    "To find the optimal technical indicator parameters for this XGBoost strategy, we build a wiget to search the parameter interactively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4907f1afde0445f6bea3c99150c57d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(IntRangeSlider(value=(10, 20), continuous_update=False, description='Chaikin', m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotutils\n",
    "replace_spec={}\n",
    "replace_spec['technical_indicator'] = {\"conf\": indicator_conf}\n",
    "replace_spec['sort_after'] = {\"load\": {'out': cached_sort}}\n",
    "plotutils.getXGBoostWidget(replace_spec, task_graph, plot_figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "In this notebook, we demoed how to use greenflow to backtest XGBoost trading strategy. It is convenient and efficient to use indicator node from the greenflow to compute features for all the stocks in the dataset in the GPU. The XGBoost training are computed in the GPU, so we can get the results quickly. This example shows the XGBoost algorithm's power in finding trading signals. We can achieve close to 2 raw Sharpe ratio in the testing time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
